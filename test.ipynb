{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4305d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088b477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Simple Pairwise Comparison (Threshold 0.85) 笘包ｸ十n",
      "Similar Merchants:\n",
      "[]\n",
      "Unique Merchants:\n",
      "['Starbucks Coffee', 'StarBucks', 'The Home Depot', 'HomeDepot', \"Lowe's\", 'Best Buy Co.', 'Best Buy']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def find_similar_merchants_simple(merchant_list, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Groups similar merchant names based on a simple pairwise similarity ratio.\n",
    "    \n",
    "    Args:\n",
    "        merchant_list (list): The list of merchant names (strings).\n",
    "        threshold (float): The minimum similarity ratio (0.0 to 1.0) to group names.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (list of similar groups, list of unique names)\n",
    "    \"\"\"\n",
    "    # Create a list of indices to keep track of which names have been grouped\n",
    "    remaining_indices = list(range(len(merchant_list)))\n",
    "    \n",
    "    # Store the groups of similar names\n",
    "    similar_groups = []\n",
    "    \n",
    "    # Process the list until all names are either grouped or deemed unique\n",
    "    while remaining_indices:\n",
    "        # Start a new group with the first remaining name\n",
    "        current_index = remaining_indices.pop(0)\n",
    "        current_name = merchant_list[current_index]\n",
    "        \n",
    "        # This will be the first group member\n",
    "        current_group = {current_name}\n",
    "        \n",
    "        # Iterate through the rest of the remaining names to find matches\n",
    "        i = 0\n",
    "        while i < len(remaining_indices):\n",
    "            check_index = remaining_indices[i]\n",
    "            check_name = merchant_list[check_index]\n",
    "            \n",
    "            # Calculate the similarity ratio\n",
    "            ratio = difflib.SequenceMatcher(None, current_name.lower(), check_name.lower()).ratio()\n",
    "            \n",
    "            if ratio >= threshold:\n",
    "                # Add to the group and remove from the remaining list\n",
    "                current_group.add(check_name)\n",
    "                remaining_indices.pop(i) # Use pop(i) to remove the element\n",
    "            else:\n",
    "                # Only increment if we didn't remove an element\n",
    "                i += 1\n",
    "        \n",
    "        # Add the group to the results\n",
    "        similar_groups.append(list(current_group))\n",
    "\n",
    "    # Identify which groups are truly \"similar\" (size > 1) and which are \"unique\" (size = 1)\n",
    "    similar_merchants = [group for group in similar_groups if len(group) > 1]\n",
    "    unique_merchants = [group[0] for group in similar_groups if len(group) == 1]\n",
    "    \n",
    "    return similar_merchants, unique_merchants\n",
    "\n",
    "# --- Example Usage ---\n",
    "merchants = [\n",
    "    \"Starbucks Coffee\",\n",
    "    \"StarBucks\",\n",
    "    \"The Home Depot\",\n",
    "    \"HomeDepot\",\n",
    "    \"Lowe's\",\n",
    "    \"Best Buy Co.\",\n",
    "    \"Best Buy\"\n",
    "]\n",
    "\n",
    "similar, unique = find_similar_merchants_simple(merchants, threshold=0.85)\n",
    "\n",
    "print(\"## Simple Pairwise Comparison (Threshold 0.55) 笘包ｸ十")\n",
    "print(f\"Similar Merchants:\\n{similar}\")\n",
    "print(f\"Unique Merchants:\\n{unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f4dc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Simple Pairwise Comparison (Threshold 0.55) 笘包ｸ十n",
      "Similar Merchants:\n",
      "[['Starbucks Coffee', 'StarBucks'], ['The Home Depot', 'HomeDepot'], ['Best Buy Co.', 'Best Buy']]\n",
      "Unique Merchants:\n",
      "[\"Lowe's\"]\n"
     ]
    }
   ],
   "source": [
    "similar, unique = find_similar_merchants_simple(merchants, threshold=0.55)\n",
    "print(\"## Simple Pairwise Comparison (Threshold 0.55) 笘包ｸ十")\n",
    "print(f\"Similar Merchants:\\n{similar}\")\n",
    "print(f\"Unique Merchants:\\n{unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f19e137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Simple Pairwise Comparison (Threshold 0.55) 笘包ｸ十n",
      "Similar Merchants:\n",
      "[['AmazonFresh BWI6', 'SQ*Local Terry AVE', 'AMZ*CARFAX Vehicle H', 'Amazon.com', 'AMZ*Legion Athletics', 'Amazon Fresh', 'AMZN Mktp US*']]\n",
      "Unique Merchants:\n",
      "['AMZ*Seed-DS-01-Daily']\n"
     ]
    }
   ],
   "source": [
    "merchants = [\n",
    "    \"Amazon Fresh\",\n",
    "    \"AmazonFresh BWI6\",\n",
    "    \"AMZ*Seed-DS-01-Daily\",\n",
    "    \"AMZ*Legion Athletics\",\n",
    "    \"AMZ*CARFAX Vehicle H\",\n",
    "    \"Amazon.com\",\n",
    "    \"SQ*Local Terry AVE\",\n",
    "    \"AMZN Mktp US*\"\n",
    "]\n",
    "\n",
    "similar, unique = find_similar_merchants_simple(merchants, threshold=0.20)\n",
    "print(\"## Simple Pairwise Comparison (Threshold 0.55) 笘包ｸ十")\n",
    "print(f\"Similar Merchants:\\n{similar}\")\n",
    "print(f\"Unique Merchants:\\n{unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d89c1b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting python-levenshtein\n",
      "  Using cached python_levenshtein-0.27.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting Levenshtein==0.27.3 (from python-levenshtein)\n",
      "  Using cached levenshtein-0.27.3-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.3->python-levenshtein)\n",
      "  Using cached rapidfuzz-3.14.3-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in d:\\projects\\era\\virtualenv\\era_gpu\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in d:\\projects\\era\\virtualenv\\era_gpu\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Using cached python_levenshtein-0.27.3-py3-none-any.whl (9.5 kB)\n",
      "Using cached levenshtein-0.27.3-cp311-cp311-win_amd64.whl (94 kB)\n",
      "Using cached scikit_learn-1.7.2-cp311-cp311-win_amd64.whl (8.9 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached rapidfuzz-3.14.3-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "Installing collected packages: fuzzywuzzy, threadpoolctl, rapidfuzz, joblib, scikit-learn, Levenshtein, python-levenshtein\n",
      "Successfully installed Levenshtein-0.27.3 fuzzywuzzy-0.18.0 joblib-1.5.2 python-levenshtein-0.27.3 rapidfuzz-3.14.3 scikit-learn-1.7.2 threadpoolctl-3.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy python-levenshtein scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e7a25b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Fuzzy Clustering with DBSCAN (EPS 0.2) 沒浬n",
      "Similar Merchants:\n",
      "[['Starbucks Coffee', 'StarBucks'], ['Best Buy Co.', 'Best Buy']]\n",
      "Unique Merchants:\n",
      "['The Home Depot', 'HomeDepot', \"Lowe's\", \"McDonald's\", 'McDonalds Corp']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "def fuzzy_clustering_dbscan(merchant_list, eps=0.2, min_samples=2):\n",
    "    \"\"\"\n",
    "    Groups similar merchant names using Levenshtein distance \n",
    "    and the DBSCAN clustering algorithm.\n",
    "    \n",
    "    Args:\n",
    "        merchant_list (list): The list of merchant names (strings).\n",
    "        eps (float): The maximum distance between two samples for one \n",
    "                     to be considered as in the neighborhood of the other (0.0 to 1.0).\n",
    "        min_samples (int): The number of samples (or total weight) in a neighborhood \n",
    "                           for a point to be considered as a core point.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (list of similar groups, list of unique names)\n",
    "    \"\"\"\n",
    "    n = len(merchant_list)\n",
    "    # 1. Create a Distance Matrix\n",
    "    # We use a distance based on the normalized Levenshtein ratio (0.0 to 1.0)\n",
    "    # Distance = 1 - (fuzz.ratio / 100)\n",
    "    # The higher the fuzz.ratio, the lower the distance (closer to 0.0)\n",
    "    distance_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            # Calculate the distance (1 - similarity)\n",
    "            # We use token_set_ratio as it is more robust to word order/extra words\n",
    "            similarity = fuzz.token_set_ratio(merchant_list[i].lower(), merchant_list[j].lower()) / 100\n",
    "            distance = 1 - similarity\n",
    "            distance_matrix[i, j] = distance_matrix[j, i] = distance\n",
    "\n",
    "    # 2. Apply DBSCAN Clustering\n",
    "    # The metric='precomputed' tells DBSCAN to use the distance_matrix directly\n",
    "    # `eps` is the max distance allowed for names to be in the same cluster.\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed').fit(distance_matrix)\n",
    "    labels = db.labels_\n",
    "\n",
    "    # 3. Group and Separate Results\n",
    "    \n",
    "    # Groups are identified by their label (0, 1, 2, ...), \n",
    "    # and \"noise\" (unique names) have a label of -1.\n",
    "    df = pd.DataFrame({'name': merchant_list, 'cluster': labels})\n",
    "    \n",
    "    similar_merchants = []\n",
    "    unique_merchants = []\n",
    "    \n",
    "    # Iterate through unique labels (clusters)\n",
    "    for label in np.unique(labels):\n",
    "        group = df[df['cluster'] == label]['name'].tolist()\n",
    "        \n",
    "        if label == -1 or len(group) == 1:\n",
    "            # -1 is noise (unique), or a group with only one member\n",
    "            unique_merchants.extend(group)\n",
    "        else:\n",
    "            # A valid cluster with multiple members\n",
    "            similar_merchants.append(group)\n",
    "            \n",
    "    return similar_merchants, unique_merchants\n",
    "\n",
    "# --- Example Usage ---\n",
    "merchants = [\n",
    "    \"Starbucks Coffee\",\n",
    "    \"StarBucks\",\n",
    "    \"The Home Depot\",\n",
    "    \"HomeDepot\",\n",
    "    \"Best Buy Co.\",\n",
    "    \"Best Buy\",\n",
    "    \"Lowe's\",\n",
    "    \"McDonald's\",\n",
    "    \"McDonalds Corp\" \n",
    "]\n",
    "\n",
    "# A lower `eps` (e.g., 0.1) means they must be very similar (90% ratio or more)\n",
    "# A higher `eps` (e.g., 0.3) means they can be less similar (70% ratio or more)\n",
    "similar_dbscan, unique_dbscan = fuzzy_clustering_dbscan(merchants, eps=0.2, min_samples=2)\n",
    "\n",
    "print(\"\\n## Fuzzy Clustering with DBSCAN (EPS 0.2) 沒浬")\n",
    "print(f\"Similar Merchants:\\n{similar_dbscan}\")\n",
    "print(f\"Unique Merchants:\\n{unique_dbscan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cce07172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Fuzzy Clustering with DBSCAN (EPS 0.2) 沒浬n",
      "Similar Merchants:\n",
      "[['Amazon Fresh', 'AmazonFresh BWI6', 'Amazon.com', 'AMZN Mktp US*'], ['AMZ*Legion Athletics', 'AMZ*CARFAX Vehicle H']]\n",
      "Unique Merchants:\n",
      "['AMZ*Seed-DS-01-Daily', 'SQ*Local Terry AVE']\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "merchants = [\n",
    "    \"Amazon Fresh\",\n",
    "    \"AmazonFresh BWI6\",\n",
    "    \"AMZ*Seed-DS-01-Daily\",\n",
    "    \"AMZ*Legion Athletics\",\n",
    "    \"AMZ*CARFAX Vehicle H\",\n",
    "    \"Amazon.com\",\n",
    "    \"SQ*Local Terry AVE\",\n",
    "    \"AMZN Mktp US*\"\n",
    "]\n",
    "\n",
    "# A lower `eps` (e.g., 0.1) means they must be very similar (90% ratio or more)\n",
    "# A higher `eps` (e.g., 0.3) means they can be less similar (70% ratio or more)\n",
    "similar_dbscan, unique_dbscan = fuzzy_clustering_dbscan(merchants, eps=0.5, min_samples=1)\n",
    "\n",
    "print(\"\\n## Fuzzy Clustering with DBSCAN (EPS 0.2) 沒浬")\n",
    "print(f\"Similar Merchants:\\n{similar_dbscan}\")\n",
    "print(f\"Unique Merchants:\\n{unique_dbscan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6784921b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "era_gpu",
   "language": "python",
   "name": "era_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
